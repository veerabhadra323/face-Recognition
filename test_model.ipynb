{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from skimage.feature import local_binary_pattern, hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for LBP\n",
    "radius = 2\n",
    "n_points = 8 * radius\n",
    "face_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and label encoder\n",
    "model_path = 'model/face_recognition_model.pkl'\n",
    "label_encoder_path = 'model/label_encoder.pkl'\n",
    "face_cascade_path = 'data/haarcascade_frontalface_default.xml'\n",
    "\n",
    "with open(model_path, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "with open(label_encoder_path, 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize face cascade\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function using HOG and LBP\n",
    "def extract_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # HOG Features\n",
    "    hog_features, _ = hog(gray, pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=True, feature_vector=True)\n",
    "    \n",
    "    # LBP Features\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    lbp_hist = lbp_hist.astype('float')\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-6)  # Normalize histogram\n",
    "    \n",
    "    return np.hstack((hog_features, lbp_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load image path\n",
    "image_path = 'Original Images/Original Images/Alia Bhatt/Alia Bhatt_15.jpg'  # Update with the path to your image\n",
    "\n",
    "\n",
    "# Read and preprocess the image\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    face = image[y:y+h, x:x+w]\n",
    "    face = cv2.resize(face, face_size)\n",
    "    features = extract_features(face)\n",
    "    \n",
    "    # Predict the label\n",
    "    label = model.predict([features])[0]\n",
    "    label_name = label_encoder.inverse_transform([label])[0]\n",
    "    \n",
    "    # Draw the label on the image\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.putText(image, label_name, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with label\n",
    "cv2.imshow('Image with Label', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
